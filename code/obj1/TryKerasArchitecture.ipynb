{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"../../KOI_Data/\"\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_sets = pd.read_csv(folder+\"/koi_sets_unb.csv\") \n",
    "mask_train = (df_sets[\"Set\"] == \"Train\").values\n",
    "mask_test = (df_sets[\"Set\"] == \"Test\").values\n",
    "mask_unlabeled = (df_sets[\"Set\"] == \"Unlabeled\").values\n",
    "\n",
    "\n",
    "df_meta = pd.read_csv(folder+\"/koi_metadata.csv\")\n",
    "df_meta_train = df_meta[mask_train]\n",
    "df_meta_test = df_meta[mask_test]\n",
    "df_meta_unb = df_meta[mask_test]\n",
    "\n",
    "y_train = ((df_meta_train[\"NExScI Disposition\"]==\"CONFIRMED\")*1).values\n",
    "y_test = ((df_meta_train[\"NExScI Disposition\"]==\"CONFIRMED\")*1).values\n",
    "\n",
    "N_train = y_train.shape[0]\n",
    "N_test = y_test.shape[0]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simmulate data (light curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4692, 70000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "T = 70000\n",
    "\n",
    "X_train = np.random.rand(N_train,T)\n",
    "X_test = np.random.rand(N_test,T)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Conv1D, Dense, Flatten, MaxPool1D, Reshape, UpSampling1D, Lambda\n",
    "from keras.layers import GlobalAveragePooling1D,GlobalMaxPool1D, TimeDistributed, GRU,LSTM, RepeatVector\n",
    "\n",
    "#def Conv1DTranspose(input_tensor, filters, kernel_size, strides=2, padding='same',activation='linear'):\n",
    "#    x = Lambda(lambda x: K.expand_dims(x, axis=2))(input_tensor)\n",
    "#    x = Conv2DTranspose(filters=filters, kernel_size=(kernel_size, 1), strides=(strides, 1), padding=padding,activation=activation)(x)\n",
    "#    x = Lambda(lambda x: K.squeeze(x, axis=2))(x)\n",
    "#    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need data with extra dim\n",
    "X_train = np.expand_dims(X_train,axis=-1)\n",
    "X_test = np.expand_dims(X_test,axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully convolutional\n",
    "---\n",
    "Opciones a cambiar y realizar:\n",
    "* AverageMaxPooling envez de GlobalMaxPooling\n",
    "* Dropout\n",
    "* BatchNormalization\n",
    "* Conv con strides y Convtranspuesta envez de **max** pooling y upsampling\n",
    "* más capas.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_model_CNN1D(input_dim, latent_dim, L=1, filters=8,kernel_s =10, pool=5):\n",
    "    #it = Input(shape=(None,1))  #variable length..\n",
    "    it = Input(shape=(input_dim,1))  #fixed length..\n",
    "    f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(it)\n",
    "    f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(f1)\n",
    "    f1 = MaxPool1D(pool)(f1) #minpooling?? -- stride..\n",
    "    #f1 = Conv1D(filters, kernel_s, strides=pool, padding='same')(f1)\n",
    "    for _ in range(L-1):\n",
    "        filters = int(filters*2)\n",
    "        f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(f1)\n",
    "        f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(f1)\n",
    "        f1 = MaxPool1D(pool)(f1)\n",
    "        #f1 = Conv1D(filters, kernel_s, strides=pool, padding='same')(f1)\n",
    "    \n",
    "    redim_shape = K.int_shape(f1)[1:] \n",
    "    d1 = GlobalMaxPool1D()(f1) #or global maxpooling\n",
    "    d1 = Dense(512,activation='relu')(d1)\n",
    "    out_latent= Dense(latent_dim, activation='linear')(d1)\n",
    "    return Model(inputs=it, outputs=out_latent), redim_shape\n",
    "\n",
    "#Conv2d!!!\n",
    "from keras.layers import Conv2D, Conv2DTranspose, MaxPool2D,UpSampling2D\n",
    "def decoder_model_CNN2D(input_dim, redim_shape, L=1, filters=8, kernel_s=10, pool=5):\n",
    "    it = Input(shape=(input_dim,))\n",
    "    d1 = Dense(512, activation='relu')(it)\n",
    "    d1 = Dense(redim_shape[-1], activation='relu')(d1)\n",
    "    f1 = RepeatVector(redim_shape[0])(d1) #inverso a maxpooling :/\n",
    "    \n",
    "    #agregar dim extra para procesar por conv2d\n",
    "    f1 = Lambda(lambda x: K.expand_dims(x, axis=2))(f1) #along channel axis\n",
    "    \n",
    "    filters = int(filters*2**(L-1))\n",
    "    for _ in range(L):\n",
    "        f1 = UpSampling2D((pool,1))(f1)\n",
    "        f1 = Conv2D(filters, (kernel_s,1), strides=1, padding='same', activation='relu')(f1)\n",
    "        f1 = Conv2D(filters, (kernel_s,1), strides=1, padding='same', activation='relu')(f1)\n",
    "        filters = int(filters/2)\n",
    "    out_x = Conv2D(1, (kernel_s,1), strides=1, padding='same', activation='linear')(f1)\n",
    "    out_x = Lambda(lambda x: K.squeeze(x, axis=-1))(out_x)\n",
    "    return Model(inputs=it, outputs=out_x)\n",
    "\n",
    "\n",
    "\"\"\" TO SLOW: DEPRECATED\"\"\"\n",
    "def decoder_model_CNN1D(input_dim, redim_shape, L=1, filters=8, kernel_s=10, pool=5):\n",
    "    it = Input(shape=(input_dim,))\n",
    "    d1 = Dense(512, activation='relu')(it)\n",
    "    d1 = Dense(int(np.prod(redim_shape)), activation='relu')(d1)\n",
    "    f1 = Reshape(redim_shape)(d1)\n",
    "    \n",
    "    filters = int(filters*2**(L-1))\n",
    "    for _ in range(L):\n",
    "        f1 = UpSampling1D(pool)(f1)\n",
    "        f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(f1)\n",
    "        f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(f1)\n",
    "        filters = int(filters/2)\n",
    "    out_x = Conv1D(1, kernel_s, strides=1, padding='same', activation='linear')(f1)\n",
    "    return Model(inputs=it, outputs=out_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convolutional and then rnn (as text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_model_CNNRNN(input_dim, latent_dim, L1=1, filters=8,kernel_s =10, pool=5, L2=1, units=32):\n",
    "    it = Input(shape=(input_dim,1)) \n",
    "    f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(it)\n",
    "    f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(f1)\n",
    "    f1 = MaxPool1D(pool)(f1)\n",
    "    for _ in range(L1-1):\n",
    "        filters = int(filters*2)\n",
    "        f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(f1)\n",
    "        f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(f1)\n",
    "        f1 = MaxPool1D(pool)(f1)\n",
    "\n",
    "    for _ in range(L2):\n",
    "        f1 = GRU(units,return_sequences=True)(f1)\n",
    "        units = int(units*2)\n",
    "    redim_shape = K.int_shape(f1)[1:] \n",
    "\n",
    "    #d1 = GlobalMaxPool1D()(f1) #or global maxpooling\n",
    "    d1 = GRU(int(units/2),return_sequences=False)(f1)\n",
    "    \n",
    "    d1 = Dense(512,activation='relu')(d1)\n",
    "    out_latent= Dense(latent_dim, activation='linear')(d1)\n",
    "    return Model(inputs=it, outputs=out_latent), redim_shape\n",
    "\n",
    "#... falta decoder..\n",
    "\n",
    "from keras.layers import Conv2D, Conv2DTranspose, MaxPool2D,UpSampling2D\n",
    "def decoder_model_CNNRNN(input_dim, redim_shape, L1=1, filters=8,kernel_s =10, pool=5, L2=1, units=32):\n",
    "    it = Input(shape=(input_dim,))\n",
    "    d1 = Dense(512, activation='relu')(it)\n",
    "    d1 = Dense(redim_shape[-1], activation='relu')(d1)\n",
    "    f1 = RepeatVector(redim_shape[0])(d1) #inverso a maxpooling :/\n",
    "    \n",
    "    units = int(units*2**(L2-1))\n",
    "    for _ in range(L2):\n",
    "        f1 = GRU(units,return_sequences=True)(f1)\n",
    "        units = int(units/2)\n",
    "            \n",
    "    #agregar dim extra para procesar por conv2d\n",
    "    f1 = Lambda(lambda x: K.expand_dims(x, axis=2))(f1) #along channel axis\n",
    "    \n",
    "    filters = int(filters*2**(L2-1))\n",
    "    for _ in range(L2):\n",
    "        f1 = UpSampling2D((pool,1))(f1)\n",
    "        f1 = Conv2D(filters, (kernel_s,1), strides=1, padding='same', activation='relu')(f1)\n",
    "        f1 = Conv2D(filters, (kernel_s,1), strides=1, padding='same', activation='relu')(f1)\n",
    "        filters = int(filters/2)\n",
    "    out_x = Conv2D(1, (kernel_s,1), strides=1, padding='same', activation='linear')(f1)\n",
    "    out_x = Lambda(lambda x: K.squeeze(x, axis=-1))(out_x)\n",
    "    return Model(inputs=it, outputs=out_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN jerárquica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_model(input_dim, latent_dim, L=1, units=8):\n",
    "    it = Input(shape=(input_dim,1))\n",
    "    #for level in range(Level:\n",
    "    \n",
    "    splits = 10\n",
    "    T_w = int(input_dim/splits) #y si sobra?...\n",
    "    f1 = Reshape([splits, T_w, 1])(it)\n",
    "    \n",
    "    aux_units = units\n",
    "    for _ in range(L):\n",
    "        f1 = TimeDistributed(GRU(aux_units, return_sequences=True))(f1)\n",
    "        aux_units = int(aux_units*2)\n",
    "    #terminar..\n",
    "    f1 = TimeDistributed(GRU(int(units/2), return_sequences=False))(f1)\n",
    "    \n",
    "    #ultimo nivel..\n",
    "    aux_units = units\n",
    "    for _ in range(L):\n",
    "        f1 = GRU(aux_units, return_sequences=True)(f1)\n",
    "        aux_units = int(aux_units*2)\n",
    "\n",
    "    redim_shape = (splits, int(f1.shape[2]))\n",
    "    redim_shape = K.int_shape(f1)[1:] \n",
    "    #terminar..\n",
    "    d1 = GRU(int(aux_units/2), return_sequences=False)(f1)\n",
    "    d1 = Dense(512, activation='relu')(d1)\n",
    "    out_latent= Dense(latent_dim, activation='linear')(d1)\n",
    "    return Model(inputs=it, outputs=out_latent), redim_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic K-max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine import Layer, InputSpec\n",
    "import tensorflow as tf\n",
    "\n",
    "class KMaxPooling(Layer):\n",
    "    \"\"\"\n",
    "    K-max pooling layer that extracts the k-highest activations from a sequence (2nd dimension). TensorFlow backend.\n",
    "    \"\"\"\n",
    "    def __init__(self, k=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_spec = InputSpec(ndim=3)\n",
    "        self.k = k\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.k, input_shape[2])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # swap last two dimensions since top_k will be applied along the last dimension\n",
    "        shifted_input = tf.transpose(inputs, [0, 2, 1])\n",
    "        # extract top_k, returns two tensors [values, indices]\n",
    "        top_k = tf.nn.top_k(shifted_input, k=self.k, sorted=True, name=None)[0] \n",
    "        return tf.transpose(top_k, [0, 2, 1])\n",
    "    \n",
    "class KMinPooling(Layer):\n",
    "    \"\"\"\n",
    "    K-max pooling layer that extracts the k-highest activations from a sequence (2nd dimension). TensorFlow backend.\n",
    "    \"\"\"\n",
    "    def __init__(self, k=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_spec = InputSpec(ndim=3)\n",
    "        self.k = k\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.k, input_shape[2])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # swap last two dimensions since top_k will be applied along the last dimension\n",
    "        shifted_input = tf.transpose(inputs, [0, 2, 1])        \n",
    "        # extract top_k, returns two tensors [values, indices]\n",
    "        top_k = -tf.nn.top_k(-shifted_input, k=self.k, sorted=True, name=None)[0] #min\n",
    "        return tf.transpose(top_k, [0, 2, 1])\n",
    "    \n",
    "import math\n",
    "def K_l(L,seq_len,k_top,layer=1): #dinamyc k-max\n",
    "    return max(k_top, math.ceil( seq_len*(L-layer)/L) )\n",
    "\n",
    "def encoder_model_KPool(input_dim, latent_dim, L=1, filters=8,kernel_s =10, K_top=500):\n",
    "    #k_top = 500 #podría ser el periodo más corto entre los datos...-- largo final de codificacion conv...\n",
    "    it = Input(shape=(input_dim,1))  #None...\n",
    "    f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(it)\n",
    "    f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(f1)\n",
    "    f1 = KMinPooling(k = K_l(L, input_dim, K_top, layer=1))(f1)\n",
    "    for l in range(L-1):\n",
    "        filters = int(filters*2)\n",
    "        f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(f1)\n",
    "        f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(f1)\n",
    "        f1 = KMinPooling(k = K_l(L, input_dim, K_top, layer=l+2))(f1) #como se desencodea??\n",
    "    redim_shape = K.int_shape(f1)[1:] \n",
    "    \n",
    "    #DUDA DE CÓMO HACER FLATTEN O GLOBAL POOL..\n",
    "    #f1 = GlobalMaxPool1D()(f1) #or global maxpooling--inverse es repeat vector..\n",
    "    f1 = Flatten()(f1)  #--- OJO CON EL DECODER..\n",
    "    \n",
    "    d1 = Dense(512,activation='relu')(f1)\n",
    "    out_latent= Dense(latent_dim, activation='linear')(d1)\n",
    "    return Model(inputs=it, outputs=out_latent), redim_shape\n",
    "\n",
    "    \n",
    "#SE NECESITA UN DECODER..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_32 (InputLayer)        (None, 70000, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 70000, 8)          88        \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 70000, 8)          648       \n",
      "_________________________________________________________________\n",
      "k_min_pooling_22 (KMinPoolin (None, 46667, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 46667, 16)         1296      \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 46667, 16)         2576      \n",
      "_________________________________________________________________\n",
      "k_min_pooling_23 (KMinPoolin (None, 23334, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 23334, 32)         5152      \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 23334, 32)         10272     \n",
      "_________________________________________________________________\n",
      "k_min_pooling_24 (KMinPoolin (None, 100, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 512)               1638912   \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 32)                16416     \n",
      "=================================================================\n",
      "Total params: 1,675,360\n",
      "Trainable params: 1,675,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#encoder, redim_shape = encoder_model_CNN2D(T, 32, L=3, filters=8, pool=5, kernel_s=10) -- deprecated\n",
    "#encoder, redim_shape = encoder_model_CNN1D(T, 32, L=3, filters=8, pool=5, kernel_s=10)\n",
    "#encoder, redim_shape = encoder_model_CNNRNN(T, 32, L1=3, filters=8, pool=5, kernel_s=10, L2=3, units=32)\n",
    "encoder, redim_shape = encoder_model_KPool(T, 32, L=3, filters=8, K_top=100)\n",
    "#encoder, redim_shape = encoder_model(T, 32, L=3, units=8)\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4999892857908157"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "70000/46667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9999571440815977"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "46667/23334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233.34"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "23334/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_30 (InputLayer)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 512)               16896     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "repeat_vector_13 (RepeatVect (None, 560, 128)          0         \n",
      "_________________________________________________________________\n",
      "gru_16 (GRU)                 (None, 560, 128)          98688     \n",
      "_________________________________________________________________\n",
      "gru_17 (GRU)                 (None, 560, 64)           37056     \n",
      "_________________________________________________________________\n",
      "gru_18 (GRU)                 (None, 560, 32)           9312      \n",
      "_________________________________________________________________\n",
      "lambda_24 (Lambda)           (None, 560, 1, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_34 (UpSampling (None, 2800, 1, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 2800, 1, 32)       10272     \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 2800, 1, 32)       10272     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_35 (UpSampling (None, 14000, 1, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 14000, 1, 16)      5136      \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 14000, 1, 16)      2576      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_36 (UpSampling (None, 70000, 1, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 70000, 1, 8)       1288      \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 70000, 1, 8)       648       \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 70000, 1, 1)       81        \n",
      "_________________________________________________________________\n",
      "lambda_25 (Lambda)           (None, 70000, 1)          0         \n",
      "=================================================================\n",
      "Total params: 257,889\n",
      "Trainable params: 257,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#decoder = decoder_model_CNN2D(32, redim_shape, L=3, filters=8, pool=5, kernel_s=10)\n",
    "decoder = decoder_model_CNNRNN(32, redim_shape, L1=3, filters=8,kernel_s =10, pool=5, L2=3, units=32)\n",
    "\n",
    "#decoder = decoder_model_CNN1D(32, redim_shape, L=3, filters=8, pool=5) --deprecated\n",
    "\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_31 (InputLayer)        (None, 70000, 1)          0         \n",
      "_________________________________________________________________\n",
      "model_28 (Model)             (None, 32)                300160    \n",
      "_________________________________________________________________\n",
      "model_30 (Model)             (None, 70000, 1)          257889    \n",
      "=================================================================\n",
      "Total params: 558,049\n",
      "Trainable params: 558,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "it = Input(shape=X_train.shape[1:])\n",
    "out = decoder(encoder(it))\n",
    "autoencoder = Model(it,out)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quizas sea necesario definir una loss ...\n",
    "autoencoder.compile(loss='mse',optimizer='adam') #focal loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,X,y,epochs=1,batch_size=32):\n",
    "    return model.fit(X,y, epochs=epochs, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3753 samples, validate on 939 samples\n",
      "Epoch 1/1\n",
      "3753/3753 [==============================] - 388s 103ms/step - loss: 0.2901 - val_loss: 0.2584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f365c7072e8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(autoencoder, X_train, X_train,batch_size=256) #conv 2d--conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3753 samples, validate on 939 samples\n",
      "Epoch 1/1\n",
      "3753/3753 [==============================] - 376s 100ms/step - loss: 0.3179 - val_loss: 0.2975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1621d91cf8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(autoencoder, X_train_a, X_train, batch_size=256) #conv1d--conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3753 samples, validate on 939 samples\n",
      "Epoch 1/1\n",
      "3753/3753 [==============================] - 371s 99ms/step - loss: 0.1696 - val_loss: 0.0885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb0d3c8b908>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(autoencoder, X_train, X_train, batch_size=256) #conv1d--conv2d -- con global pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3753 samples, validate on 939 samples\n",
      "Epoch 1/1\n",
      "3753/3753 [==============================] - 485s 129ms/step - loss: 0.2148 - val_loss: 0.1565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac3acde0b8>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(autoencoder, X_train, X_train, batch_size=256) #conv1dRNN -- RNNconv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4692, 70000, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_hat = autoencoder.predict(X_train)\n",
    "X_train_encoder = encoder.predict(X_train)\n",
    "X_train_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4692, 32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                F1 macro  F1 micro    F1 raw  F1 weighted  Precision raw  \\\n",
      "False Positive  0.274583  0.274583  0.000000     0.207868       0.000000   \n",
      "Confirmed       0.274583  0.274583  0.549165     0.207868       0.378517   \n",
      "\n",
      "                Recall raw  \n",
      "False Positive         0.0  \n",
      "Confirmed              1.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/fmena/anaconda3/envs/tesis/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/users/fmena/anaconda3/envs/tesis/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from evaluation import calculate_metrics\n",
    "aux = calculate_metrics(y_train,np.ones((N_train,1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tesis]",
   "language": "python",
   "name": "conda-env-tesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
