{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"../../KOI_Data/\"\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_sets = pd.read_csv(folder+\"/koi_sets_unb.csv\") \n",
    "mask_train = (df_sets[\"Set\"] == \"Train\").values\n",
    "mask_test = (df_sets[\"Set\"] == \"Test\").values\n",
    "mask_unlabeled = (df_sets[\"Set\"] == \"Unlabeled\").values\n",
    "\n",
    "\n",
    "df_meta = pd.read_csv(folder+\"/koi_metadata.csv\")\n",
    "df_meta_train = df_meta[mask_train]\n",
    "df_meta_test = df_meta[mask_test]\n",
    "df_meta_unb = df_meta[mask_test]\n",
    "\n",
    "y_train = ((df_meta_train[\"NExScI Disposition\"]==\"CONFIRMED\")*1).values\n",
    "y_test = ((df_meta_train[\"NExScI Disposition\"]==\"CONFIRMED\")*1).values\n",
    "\n",
    "N_train = y_train.shape[0]\n",
    "N_test = y_test.shape[0]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simmulate data (light curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4692, 70000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "T = 70000\n",
    "\n",
    "X_train = np.random.rand(N_train,T)\n",
    "X_test = np.random.rand(N_test,T)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input,Conv1D,Dense,Flatten, MaxPool1D, Reshape,UpSampling1D\n",
    "from keras.layers import GlobalAveragePooling1D,GlobalMaxPool1D, TimeDistributed, GRU,LSTM\n",
    "\n",
    "#def Conv1DTranspose(input_tensor, filters, kernel_size, strides=2, padding='same',activation='linear'):\n",
    "#    x = Lambda(lambda x: K.expand_dims(x, axis=2))(input_tensor)\n",
    "#    x = Conv2DTranspose(filters=filters, kernel_size=(kernel_size, 1), strides=(strides, 1), padding=padding,activation=activation)(x)\n",
    "#    x = Lambda(lambda x: K.squeeze(x, axis=2))(x)\n",
    "#    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need data with extra dim\n",
    "X_train = np.expand_dims(X_train,axis=-1)\n",
    "X_test = np.expand_dims(X_test,axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropa or BN??\n",
    "\n",
    "def encoder_model(input_dim, latent_dim, L=1, filters=8,kernel_s =10, pool=5):\n",
    "    it = Input(shape=(input_dim,1)) \n",
    "    f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(it)\n",
    "    f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(f1)\n",
    "    f1 = MaxPool1D(pool)(f1)\n",
    "    for _ in range(L-1):\n",
    "        filters = int(filters*2)\n",
    "        f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(f1)\n",
    "        f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(f1)\n",
    "        f1 = MaxPool1D(pool)(f1)\n",
    "\n",
    "    #d1 = GlobalMaxPool1D()(f1) #or global maxpooling\n",
    "    redim_shape = (int(f1.shape[1]),int(f1.shape[2]))\n",
    "    d1 = Flatten()(f1) \n",
    "    d1 = Dense(512,activation='relu')(d1)\n",
    "    out_latent= Dense(latent_dim, activation='linear')(d1)\n",
    "    return Model(inputs=it, outputs=out_latent), redim_shape\n",
    "\n",
    "def decoder_model(input_dim, redim_shape, L=1, filters=8, kernel_s=10, pool=5):\n",
    "    it = Input(shape=(input_dim,))\n",
    "    d1 = Dense(512, activation='relu')(it)\n",
    "    d1 = Dense(int(np.prod(redim_shape)), activation='relu')(d1)\n",
    "    f1 = Reshape(redim_shape)(d1)\n",
    "    \n",
    "    filters = int(filters*2**(L-1))\n",
    "    for _ in range(L):\n",
    "        f1 = UpSampling1D(pool)(f1)\n",
    "        f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(f1)\n",
    "        f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(f1)\n",
    "        filters = int(filters/2)\n",
    "    out_x = Conv1D(1, kernel_s, strides=1, padding='same', activation='linear')(f1)\n",
    "    return Model(inputs=it, outputs=out_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convolutional and then rnn (as text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_model(input_dim, latent_dim, L1=1, filters=8,kernel_s =10, pool=5, L2=1, units=32):\n",
    "    it = Input(shape=(input_dim,1)) \n",
    "    f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(it)\n",
    "    f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(f1)\n",
    "    f1 = MaxPool1D(pool)(f1)\n",
    "    for _ in range(L1-1):\n",
    "        filters = int(filters*2)\n",
    "        f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(f1)\n",
    "        f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(f1)\n",
    "        f1 = MaxPool1D(pool)(f1)\n",
    "    T = f1.shape[1]\n",
    "    for _ in range(L2):\n",
    "        f1 = GRU(units,return_sequences=True)(f1)\n",
    "        units = int(units*2)\n",
    "    redim_shape = (int(T),int(f1.shape[2]))\n",
    "    #global max pooling?\n",
    "    #d1 = GlobalMaxPool1D()(f1) #or global maxpooling\n",
    "    d1 = GRU(int(units/2),return_sequences=False)(f1)\n",
    "    d1 = Dense(512,activation='relu')(d1)\n",
    "    out_latent= Dense(latent_dim, activation='linear')(d1)\n",
    "    return Model(inputs=it, outputs=out_latent), redim_shape\n",
    "\n",
    "#... falta decoder.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN jerárquica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_model(input_dim, latent_dim, L=1, units=8):\n",
    "    it = Input(shape=(input_dim,1))\n",
    "    #for level in range(Level:\n",
    "    \n",
    "    splits = 10\n",
    "    T_w = int(input_dim/splits) #y si sobra?...\n",
    "    f1 = Reshape([splits, T_w, 1])(it)\n",
    "    \n",
    "    aux_units = units\n",
    "    for _ in range(L):\n",
    "        f1 = TimeDistributed(GRU(aux_units, return_sequences=True))(f1)\n",
    "        aux_units = int(aux_units*2)\n",
    "    #terminar..\n",
    "    f1 = TimeDistributed(GRU(int(units/2), return_sequences=False))(f1)\n",
    "    \n",
    "    #ultimo nivel..\n",
    "    aux_units = units\n",
    "    for _ in range(L):\n",
    "        f1 = GRU(aux_units, return_sequences=True)(f1)\n",
    "        aux_units = int(aux_units*2)\n",
    "\n",
    "    redim_shape = (splits, int(f1.shape[2]))\n",
    "    #terminar..\n",
    "    d1 = GRU(int(aux_units/2), return_sequences=False)(f1)\n",
    "    d1 = Dense(512, activation='relu')(d1)\n",
    "    out_latent= Dense(latent_dim, activation='linear')(d1)\n",
    "    return Model(inputs=it, outputs=out_latent), redim_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic K-max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine import Layer, InputSpec\n",
    "import tensorflow as tf\n",
    "\n",
    "class KMaxPooling(Layer):\n",
    "    \"\"\"\n",
    "    K-max pooling layer that extracts the k-highest activations from a sequence (2nd dimension). TensorFlow backend.\n",
    "    \"\"\"\n",
    "    def __init__(self, k=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_spec = InputSpec(ndim=3)\n",
    "        self.k = k\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.k, input_shape[2])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # swap last two dimensions since top_k will be applied along the last dimension\n",
    "        shifted_input = tf.transpose(inputs, [0, 2, 1])\n",
    "        \n",
    "        # extract top_k, returns two tensors [values, indices]\n",
    "        top_k = tf.nn.top_k(shifted_input, k=self.k, sorted=True, name=None)[0] \n",
    "        top_k = -tf.nn.top_k(-shifted_input, k=self.k, sorted=True, name=None)[0] #min\n",
    "        return tf.transpose(top_k, [0, 2, 1])\n",
    "    \n",
    "import math\n",
    "def K_l(L,seq_len,k_top,layer=1): #dinamyc k-max\n",
    "    return max(k_top, math.ceil( seq_len*(L-layer)/L) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_model(input_dim, latent_dim, L=1, filters=8,kernel_s =10, pool=5, K_top=500):\n",
    "    #k_top = 500 #podría ser el periodo más corto entre los datos...-- largo final de codificacion conv...\n",
    "    it = Input(shape=(input_dim,1)) \n",
    "    f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(it)\n",
    "    f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(f1)\n",
    "    f1 = KMaxPooling(k = K_l(L, input_dim, K_top, layer=1))(f1)\n",
    "    for l in range(L-1):\n",
    "        filters = int(filters*2)\n",
    "        f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(f1)\n",
    "        f1 = Conv1D(filters, kernel_s, strides=1, padding='same', activation='relu')(f1)\n",
    "        f1 = KMaxPooling(k = K_l(L, input_dim, K_top, layer=l+2))(f1) #como se desencodea??\n",
    "\n",
    "    #d1 = GlobalMaxPool1D()(f1) #or global maxpooling--inverse es repeat vector..\n",
    "    redim_shape = (int(f1.shape[1]),int(f1.shape[2]))\n",
    "    d1 = Flatten()(f1) \n",
    "    d1 = Dense(512,activation='relu')(d1)\n",
    "    out_latent= Dense(latent_dim, activation='linear')(d1)\n",
    "    return Model(inputs=it, outputs=out_latent), redim_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 70000, 1)          0         \n",
      "_________________________________________________________________\n",
      "reshape_9 (Reshape)          (None, 10, 7000, 1)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_16 (TimeDis (None, 10, 7000, 8)       240       \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 10, 7000, 16)      1200      \n",
      "_________________________________________________________________\n",
      "time_distributed_18 (TimeDis (None, 10, 7000, 32)      4704      \n",
      "_________________________________________________________________\n",
      "time_distributed_19 (TimeDis (None, 10, 4)             444       \n",
      "_________________________________________________________________\n",
      "gru_30 (GRU)                 (None, 10, 8)             312       \n",
      "_________________________________________________________________\n",
      "gru_31 (GRU)                 (None, 10, 16)            1200      \n",
      "_________________________________________________________________\n",
      "gru_32 (GRU)                 (None, 10, 32)            4704      \n",
      "_________________________________________________________________\n",
      "gru_33 (GRU)                 (None, 32)                6240      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               16896     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                16416     \n",
      "=================================================================\n",
      "Total params: 52,356\n",
      "Trainable params: 52,356\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#encoder, redim_shape = encoder_model(T, 32, L=3, filters=8, pool=5)\n",
    "#encoder, redim_shape = encoder_model(T, 32, L1=3, filters=8, pool=5,L2=3, units=32)\n",
    "#encoder, redim_shape = encoder_model(T, 32, L=3, filters=8, pool=5, K_top=100)\n",
    "encoder, redim_shape = encoder_model(T, 32, L=3, units=8)\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               16896     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 17920)             9192960   \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 560, 32)           0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_20 (UpSampling (None, 2800, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 2800, 32)          10272     \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 2800, 32)          10272     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_21 (UpSampling (None, 14000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 14000, 16)         5136      \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 14000, 16)         2576      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_22 (UpSampling (None, 70000, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 70000, 8)          1288      \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 70000, 8)          648       \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 70000, 1)          81        \n",
      "=================================================================\n",
      "Total params: 9,240,129\n",
      "Trainable params: 9,240,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = decoder_model(32, redim_shape, L=3, filters=8, pool=5)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-5cb4fd76a234>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mautoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decoder' is not defined"
     ]
    }
   ],
   "source": [
    "it = Input(shape=(T,1))\n",
    "out = decoder(encoder(it))\n",
    "autoencoder = Model(it,out)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-e8b4b5ade251>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#quizas sea necesario definir una loss ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#focal loss?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "#quizas sea necesario definir una loss ...\n",
    "autoencoder.compile(loss='mse',optimizer='adam') #focal loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,X,y,epochs=1,batch_size=32):\n",
    "    return model.fit(X,y, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3753 samples, validate on 939 samples\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "train_model(autoencoder, X_train, X_train,batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                F1 macro  F1 micro    F1 raw  F1 weighted  Precision raw  \\\n",
      "False Positive  0.274583  0.274583  0.000000     0.207868       0.000000   \n",
      "Confirmed       0.274583  0.274583  0.549165     0.207868       0.378517   \n",
      "\n",
      "                Recall raw  \n",
      "False Positive         0.0  \n",
      "Confirmed              1.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/fmena/anaconda3/envs/tesis/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/users/fmena/anaconda3/envs/tesis/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from evaluation import calculate_metrics\n",
    "aux = calculate_metrics(y_train,np.ones((N_train,1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tesis]",
   "language": "python",
   "name": "conda-env-tesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
