{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Save con Nodos\n",
    "import os\n",
    "from keras.models import load_model\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os, sys\n",
    "dirpath = os.getcwd().split(\"code\")[0]+\"code/\"\n",
    "sys.path.append(dirpath)\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from evaluation import calculate_metrics\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "import pandas as pd\n",
    "from keras.regularizers import l2\n",
    "from keras.activations import tanh\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.losses import categorical_crossentropy,binary_crossentropy\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from time import time\n",
    "import random\n",
    "from random import shuffle,seed\n",
    "from sklearn.metrics import classification_report\n",
    "import math\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.backend import eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "import time\n",
    "\n",
    "def plot_confusion_matrix(cm, target_names, title='Confusion matrix (f1-score)',cmap=None, normalize=True):\n",
    "    \n",
    "    import itertools\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KOI Name</th>\n",
       "      <th>Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K00889.01</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K01009.01</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K07621.01</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K06252.01</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K00958.01</td>\n",
       "      <td>Unlabeled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    KOI Name        Set\n",
       "0  K00889.01       Test\n",
       "1  K01009.01      Train\n",
       "2  K07621.01      Train\n",
       "3  K06252.01      Train\n",
       "4  K00958.01  Unlabeled"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold = \"../../KOI_Data/\"\n",
    "df_sets = pd.read_csv(fold+\"/koi_sets_unb.csv\") \n",
    "mask_train = (df_sets[\"Set\"] == \"Train\").values\n",
    "mask_test = (df_sets[\"Set\"] == \"Test\").values\n",
    "mask_unlabeled = (df_sets[\"Set\"] == \"Unlabeled\").values\n",
    "df_sets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KOI Name</th>\n",
       "      <th>NExScI Disposition</th>\n",
       "      <th>Kepler Name</th>\n",
       "      <th>Period</th>\n",
       "      <th>Time of Transit Epoch</th>\n",
       "      <th>First Transit Time (BJD)</th>\n",
       "      <th>Impact Parameter</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Transit Depth</th>\n",
       "      <th>r/R</th>\n",
       "      <th>...</th>\n",
       "      <th>Teff</th>\n",
       "      <th>log(g)</th>\n",
       "      <th>Metallicity</th>\n",
       "      <th>Stellar Radius</th>\n",
       "      <th>Stellar Mass</th>\n",
       "      <th>Max single event sigma</th>\n",
       "      <th>Max Multievent sigma</th>\n",
       "      <th>Transit Model SNR</th>\n",
       "      <th>KOI count</th>\n",
       "      <th>Transit Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K01009.01</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.092465</td>\n",
       "      <td>357.53594</td>\n",
       "      <td>2455190.536</td>\n",
       "      <td>0.161</td>\n",
       "      <td>3.65900</td>\n",
       "      <td>254.0</td>\n",
       "      <td>0.014</td>\n",
       "      <td>...</td>\n",
       "      <td>5037.0</td>\n",
       "      <td>4.547</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.727</td>\n",
       "      <td>3.648</td>\n",
       "      <td>15.175</td>\n",
       "      <td>17.1</td>\n",
       "      <td>1</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K07621.01</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>275.073650</td>\n",
       "      <td>315.24860</td>\n",
       "      <td>2455148.249</td>\n",
       "      <td>0.595</td>\n",
       "      <td>3.37000</td>\n",
       "      <td>228.9</td>\n",
       "      <td>0.014</td>\n",
       "      <td>...</td>\n",
       "      <td>5604.0</td>\n",
       "      <td>4.226</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>1.187</td>\n",
       "      <td>0.864</td>\n",
       "      <td>5.909</td>\n",
       "      <td>8.012</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K06252.01</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.460439</td>\n",
       "      <td>133.77449</td>\n",
       "      <td>2454966.774</td>\n",
       "      <td>1.061</td>\n",
       "      <td>4.73492</td>\n",
       "      <td>76412.9</td>\n",
       "      <td>0.478</td>\n",
       "      <td>...</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>4.638</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.796</td>\n",
       "      <td>452.526</td>\n",
       "      <td>3704.503</td>\n",
       "      <td>1797.4</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K04162.01</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539366</td>\n",
       "      <td>131.97457</td>\n",
       "      <td>2454964.975</td>\n",
       "      <td>0.988</td>\n",
       "      <td>5.43400</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.016</td>\n",
       "      <td>...</td>\n",
       "      <td>6341.0</td>\n",
       "      <td>3.301</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>5.302</td>\n",
       "      <td>2.050</td>\n",
       "      <td>4.847</td>\n",
       "      <td>9.076</td>\n",
       "      <td>57.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>K00998.01</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161.788327</td>\n",
       "      <td>214.03900</td>\n",
       "      <td>2455047.039</td>\n",
       "      <td>0.267</td>\n",
       "      <td>5.31000</td>\n",
       "      <td>87750.0</td>\n",
       "      <td>0.273</td>\n",
       "      <td>...</td>\n",
       "      <td>6018.0</td>\n",
       "      <td>4.327</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.212</td>\n",
       "      <td>1.142</td>\n",
       "      <td>341.666</td>\n",
       "      <td>806.993</td>\n",
       "      <td>704.5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    KOI Name NExScI Disposition Kepler Name      Period  \\\n",
       "1  K01009.01     FALSE POSITIVE         NaN    5.092465   \n",
       "2  K07621.01     FALSE POSITIVE         NaN  275.073650   \n",
       "3  K06252.01     FALSE POSITIVE         NaN    8.460439   \n",
       "6  K04162.01     FALSE POSITIVE         NaN    0.539366   \n",
       "9  K00998.01     FALSE POSITIVE         NaN  161.788327   \n",
       "\n",
       "   Time of Transit Epoch  First Transit Time (BJD)  Impact Parameter  \\\n",
       "1              357.53594               2455190.536             0.161   \n",
       "2              315.24860               2455148.249             0.595   \n",
       "3              133.77449               2454966.774             1.061   \n",
       "6              131.97457               2454964.975             0.988   \n",
       "9              214.03900               2455047.039             0.267   \n",
       "\n",
       "   Duration  Transit Depth    r/R  ...    Teff  log(g)  Metallicity  \\\n",
       "1   3.65900          254.0  0.014  ...  5037.0   4.547        -0.20   \n",
       "2   3.37000          228.9  0.014  ...  5604.0   4.226        -0.12   \n",
       "3   4.73492        76412.9  0.478  ...  5951.0   4.638        -1.06   \n",
       "6   5.43400          145.0  0.016  ...  6341.0   3.301        -0.10   \n",
       "9   5.31000        87750.0  0.273  ...  6018.0   4.327         0.18   \n",
       "\n",
       "   Stellar Radius  Stellar Mass  Max single event sigma  Max Multievent sigma  \\\n",
       "1           0.751         0.727                   3.648                15.175   \n",
       "2           1.187         0.864                   5.909                 8.012   \n",
       "3           0.702         0.796                 452.526              3704.503   \n",
       "6           5.302         2.050                   4.847                 9.076   \n",
       "9           1.212         1.142                 341.666               806.993   \n",
       "\n",
       "   Transit Model SNR  KOI count  Transit Number  \n",
       "1               17.1          1             225  \n",
       "2                7.5          1               4  \n",
       "3             1797.4          1             164  \n",
       "6               57.6          1            1239  \n",
       "9              704.5          1               9  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta = pd.read_csv(fold+\"/koi_metadata.csv\")\n",
    "df_meta_train = df_meta[mask_train]\n",
    "df_meta_test = df_meta[mask_test]\n",
    "df_meta_unb = df_meta[mask_unlabeled]\n",
    "\n",
    "df_meta_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kois_train=df_meta_train['KOI Name'].values\n",
    "labels_train=df_meta_train['NExScI Disposition'].values\n",
    "kois_val=df_meta_test['KOI Name'].values\n",
    "labels_val=df_meta_test['NExScI Disposition'].values\n",
    "kois_test=df_meta_unb['KOI Name'].values\n",
    "labels_test=df_meta_unb['NExScI Disposition'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FALSE POSITIVE', 'FALSE POSITIVE', 'FALSE POSITIVE',\n",
       "       'FALSE POSITIVE', 'FALSE POSITIVE'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_int(labels):\n",
    "    y_true=[]\n",
    "    for y in labels:\n",
    "        if y=='CONFIRMED':\n",
    "            y_true.append(1)\n",
    "        else:\n",
    "            y_true.append(0)\n",
    "    return y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrices manuales\n",
    "\n",
    "### Sólo en sentido izq-der"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MTF_u15_d30.npy',\n",
       " 'MTF_u10_d30.npy',\n",
       " 'MTF_u15_d20.npy',\n",
       " 'MTF_u10_d20.npy',\n",
       " 'MTF_u5_d20.npy',\n",
       " 'MTF_u5_d15.npy',\n",
       " 'MTF_u5_d10.npy',\n",
       " 'MTF_u5_d30.npy',\n",
       " 'MTF_u10_d10.npy',\n",
       " 'MTF_u10_d15.npy',\n",
       " 'MTF_u15_d15.npy',\n",
       " 'MTF_u15_d10.npy']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listdir('/work/work_teamEXOPLANET/MTF_margarita/no_invertidos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class2int(labels):\n",
    "    y=[]\n",
    "    for lab in labels:\n",
    "        if lab=='FALSE POSITIVE':\n",
    "            y.append(0)\n",
    "        else:\n",
    "            y.append(1)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "matrices=np.load('/work/work_teamEXOPLANET/MTF_margarita/no_invertidos/MTF_u10_d30.npy')\n",
    "\n",
    "x_train=matrices[mask_train]\n",
    "y_train=class2int(labels_train)\n",
    "\n",
    "x_val=matrices[mask_test]\n",
    "y_val=class2int(labels_val)\n",
    "\n",
    "x_test=matrices[mask_unlabeled]\n",
    "#y_test=#predecir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objetos de entrenamiento: (4692, 40, 40, 1)\n",
      "Objetos de validación: (1565, 40, 40, 1)\n",
      "Objetos de testing: (1797, 40, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "#all_kois=np.concatenate([np.asarray(kois_fp),np.asarray(kois_con)])\n",
    "x_train=np.expand_dims(np.asarray(x_train), axis=-1)\n",
    "x_val=np.expand_dims(np.asarray(x_val), axis=-1)\n",
    "x_test=np.expand_dims(np.asarray(x_test), axis=-1)\n",
    "\n",
    "print (\"Objetos de entrenamiento:\",x_train.shape)\n",
    "print (\"Objetos de validación:\",x_val.shape)\n",
    "print (\"Objetos de testing:\",x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80452675 1.32094595]\n"
     ]
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)#{0: 3.,   1: 6.,   2: 5.,  3: 3.}\n",
    "print (class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 40, 40, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 39, 39, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 39, 39, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 39, 39, 128)       204928    \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 39, 39, 256)       819456    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 1,419,777\n",
      "Trainable params: 1,419,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(40,40,1), strides=(1, 1),activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D((2,2), strides=(1,1)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv2D(128, (5, 5), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model.add(Conv2D(256, (5, 5), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "#model.add(Flatten())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 40, 40, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 20, 20, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 20, 20, 256)       295168    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 468,481\n",
      "Trainable params: 468,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv2D(64, (3, 3), input_shape=(40,40,1), strides=(1, 1),activation=\"relu\", padding=\"same\"))\n",
    "model1.add(MaxPooling2D((2,2)))\n",
    "model1.add(Dropout(0.1))\n",
    "model1.add(Conv2D(128, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model1.add(Conv2D(256, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "#model1.add(Flatten())\n",
    "model1.add(GlobalAveragePooling2D())\n",
    "model1.add(Dense(256,activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.summary()\n",
    "\n",
    "model1.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4692 samples, validate on 1565 samples\n",
      "Epoch 1/50\n",
      "4692/4692 [==============================] - 68s 14ms/step - loss: 0.5903 - acc: 0.6360 - val_loss: 0.5926 - val_acc: 0.5546\n",
      "Epoch 2/50\n",
      "4692/4692 [==============================] - 67s 14ms/step - loss: 0.5580 - acc: 0.6405 - val_loss: 0.6061 - val_acc: 0.5284\n",
      "Epoch 3/50\n",
      "4692/4692 [==============================] - 66s 14ms/step - loss: 0.5548 - acc: 0.6413 - val_loss: 0.5941 - val_acc: 0.5559\n",
      "Epoch 4/50\n",
      "4692/4692 [==============================] - 66s 14ms/step - loss: 0.5523 - acc: 0.6473 - val_loss: 0.5980 - val_acc: 0.5502\n",
      "Epoch 5/50\n",
      "4692/4692 [==============================] - 67s 14ms/step - loss: 0.5543 - acc: 0.6507 - val_loss: 0.6139 - val_acc: 0.5399\n",
      "Epoch 6/50\n",
      "4692/4692 [==============================] - 67s 14ms/step - loss: 0.5581 - acc: 0.6413 - val_loss: 0.6141 - val_acc: 0.5240\n",
      "Epoch 7/50\n",
      "4692/4692 [==============================] - 67s 14ms/step - loss: 0.5503 - acc: 0.6385 - val_loss: 0.5934 - val_acc: 0.5649\n",
      "Epoch 8/50\n",
      "4692/4692 [==============================] - 67s 14ms/step - loss: 0.5558 - acc: 0.6377 - val_loss: 0.5965 - val_acc: 0.5502\n",
      "Epoch 9/50\n",
      "4692/4692 [==============================] - 66s 14ms/step - loss: 0.5543 - acc: 0.6462 - val_loss: 0.6148 - val_acc: 0.5284\n",
      "Epoch 10/50\n",
      "4692/4692 [==============================] - 66s 14ms/step - loss: 0.5498 - acc: 0.6436 - val_loss: 0.6095 - val_acc: 0.5342\n",
      "Epoch 11/50\n",
      "4692/4692 [==============================] - 66s 14ms/step - loss: 0.5519 - acc: 0.6496 - val_loss: 0.6030 - val_acc: 0.5323\n",
      "Epoch 12/50\n",
      "4692/4692 [==============================] - 66s 14ms/step - loss: 0.5517 - acc: 0.6415 - val_loss: 0.6002 - val_acc: 0.5482\n",
      "Epoch 13/50\n",
      "4692/4692 [==============================] - 67s 14ms/step - loss: 0.5495 - acc: 0.6498 - val_loss: 0.6195 - val_acc: 0.5195\n",
      "Epoch 14/50\n",
      "4692/4692 [==============================] - 67s 14ms/step - loss: 0.5511 - acc: 0.6396 - val_loss: 0.6060 - val_acc: 0.5412\n",
      "Epoch 15/50\n",
      "4692/4692 [==============================] - 67s 14ms/step - loss: 0.5479 - acc: 0.6460 - val_loss: 0.5893 - val_acc: 0.5559\n",
      "Epoch 16/50\n",
      "4692/4692 [==============================] - 67s 14ms/step - loss: 0.5484 - acc: 0.6488 - val_loss: 0.6043 - val_acc: 0.5259\n",
      "Epoch 17/50\n",
      "3328/4692 [====================>.........] - ETA: 18s - loss: 0.5473 - acc: 0.6541"
     ]
    }
   ],
   "source": [
    "hist=model.fit(x_train, y_train, batch_size=64, epochs=50, verbose=1, class_weight=class_weights, validation_data=(x_val,y_val))\n",
    "plt.plot(hist.history['loss'],label=\"train_loss\")\n",
    "plt.plot(hist.history['val_loss'],label=\"val_loss\")\n",
    "plt.title(\"Model Loss BCE CNN\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist.history['acc'],label=\"Train accuracy\" )\n",
    "plt.plot(hist.history['val_acc'],label=\"Val accuracy\" )\n",
    "plt.title(\"Model Accuracy BCE CNN\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predichos=model.predict_classes(x_val)\n",
    "print (calculate_metrics(y_val,predichos,'[VAL] Confusion Matrix 50 epochs CNN + reverse LC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist1=model1.fit(x_train, y_train, batch_size=64, epochs=50, verbose=1, class_weight=class_weights, validation_data=(x_val,y_val))\n",
    "plt.plot(hist1.history['loss'],label=\"train_loss\")\n",
    "plt.plot(hist1.history['val_loss'],label=\"val_loss\")\n",
    "plt.title(\"Model Loss BCE CNN1\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist1.history['acc'],label=\"Train accuracy\" )\n",
    "plt.plot(hist1.history['val_acc'],label=\"Val accuracy\" )\n",
    "plt.title(\"Model Accuracy BCE CNN1\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predichos=model1.predict_classes(x_val)\n",
    "print (calculate_metrics(y_val,predichos,'[VAL] Confusion Matrix 50 epochs CNN 1 + Reverse LC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=2., weights=1):   #weights np.asarray()\n",
    "    weights= K.variable(weights)\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_true = K.clip(y_true, K.epsilon(),1)\n",
    "        y_pred = K.clip(y_pred,K.epsilon(),1)\n",
    "        return - K.sum(weights* K.pow(1. - y_pred, gamma)* y_true * K.log(y_pred), axis=-1) \n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(64, (3, 3), input_shape=(40,40,1), strides=(1, 1),activation=\"relu\", padding=\"same\"))\n",
    "model2.add(MaxPooling2D((2,2)))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Conv2D(128, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model2.add(Conv2D(256, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "#model1.add(Flatten())\n",
    "model2.add(GlobalAveragePooling2D())\n",
    "model2.add(Dense(256,activation='relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dense(2, activation='softmax'))\n",
    "model2.summary()\n",
    "\n",
    "model2.compile(loss=focal_loss(2,weights=class_weights),optimizer='adam',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat=to_categorical(y_train, 2)\n",
    "y_train_cat[:3]\n",
    "y_val_cat=to_categorical(y_val, 2)\n",
    "y_val_cat[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist2=model2.fit(x_train, y_train_cat, batch_size=64, epochs=50, verbose=1, class_weight=class_weights, validation_data=(x_val,y_val_cat))\n",
    "plt.plot(hist2.history['loss'],label=\"train_loss\")\n",
    "plt.plot(hist2.history['val_loss'],label=\"val_loss\")\n",
    "plt.title(\"Model Loss Focal CNN1 + Reverse LC\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist2.history['acc'],label=\"Train accuracy\" )\n",
    "plt.plot(hist2.history['val_acc'],label=\"Val accuracy\" )\n",
    "plt.title(\"Model Accuracy Focal CNN1 + Reverse LC\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predichos=model2.predict_classes(x_val)\n",
    "print (calculate_metrics(y_val,predichos,'[VAL] Confusion Matrix 50 epochs CNN 1 Focal + Reverse LC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segundo Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Conv2D(32, (3, 3), input_shape=(40,40,1), strides=(1, 1),activation=\"relu\", padding=\"same\"))\n",
    "model3.add(Dropout(0.25))\n",
    "model3.add(Conv2D(32, (3, 3), input_shape=(40,40,1), strides=(1, 1),activation=\"relu\", padding=\"same\"))\n",
    "model3.add(Dropout(0.15))\n",
    "model3.add(GlobalAveragePooling2D())\n",
    "model3.add(Dense(256, activation='relu'))\n",
    "model3.add(Dropout(0.25))\n",
    "model3.add(Dense(128,activation='relu'))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Conv2D(32, (3, 3), input_shape=(40,40,1), strides=(1, 1),activation=\"relu\", padding=\"same\"))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Conv2D(32, (3, 3), input_shape=(40,40,1), strides=(1, 1),activation=\"relu\", padding=\"same\"))\n",
    "model4.add(Dropout(0.1))\n",
    "model4.add(GlobalAveragePooling2D())\n",
    "model4.add(Dense(256, activation='relu'))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Dense(128, activation='relu'))\n",
    "model4.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model4.compile(loss=focal_loss(2,weights=class_weights),optimizer='adam',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist3=model3.fit(x_train, y_train, batch_size=64, epochs=100, verbose=1, class_weight=class_weights, validation_data=(x_val,y_val))\n",
    "plt.plot(hist3.history['loss'],label=\"train_loss\")\n",
    "plt.plot(hist3.history['val_loss'],label=\"val_loss\")\n",
    "plt.title(\"Model Loss BCE CNN 3 + Reverse LC\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist3.history['acc'],label=\"Train accuracy\" )\n",
    "plt.plot(hist3.history['val_acc'],label=\"Val accuracy\" )\n",
    "plt.title(\"Model Accuracy BCE CNN 3 + Reverse LC\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "predichos=model3.predict_classes(x_val)\n",
    "print (calculate_metrics(y_val,predichos,'[VAL] Confusion Matrix 50 epochs CNN 3 BCE + Reverse LC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist4=model4.fit(x_train, y_train_cat, batch_size=64, epochs=100, verbose=1, class_weight=class_weights, validation_data=(x_val,y_val_cat))\n",
    "plt.plot(hist4.history['loss'],label=\"train_loss\")\n",
    "plt.plot(hist4.history['val_loss'],label=\"val_loss\")\n",
    "plt.title(\"Model Loss Focal CNN4 + Reverse LC\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist4.history['acc'],label=\"Train accuracy\" )\n",
    "plt.plot(hist4.history['val_acc'],label=\"Val accuracy\" )\n",
    "plt.title(\"Model Accuracy Focal CNN4 + Reverse LC\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "predichos=model4.predict_classes(x_val)\n",
    "print (calculate_metrics(y_val,predichos,'[VAL] Confusion Matrix 50 epochs CNN 1 Focal + Reverse LC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mini-batches ?\n",
    "hist3=model3.fit(x_train, y_train, batch_size=256 , epochs=50, verbose=1, class_weight=class_weights, validation_data=(x_val,y_val))\n",
    "plt.plot(hist3.history['loss'],label=\"train_loss\")\n",
    "plt.plot(hist3.history['val_loss'],label=\"val_loss\")\n",
    "plt.title(\"Model Loss BCE CNN  + Reverse LC\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist3.history['acc'],label=\"Train accuracy\" )\n",
    "plt.plot(hist3.history['val_acc'],label=\"Val accuracy\" )\n",
    "plt.title(\"Model Accuracy BCE CNN  + Reverse LC\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "predichos=model3.predict_classes(x_val)\n",
    "print (calculate_metrics(y_val,predichos,'[VAL] Confusion Matrix 50 epochs CNN BCE + Reverse LC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model7 = Sequential()\n",
    "model7.add(Conv2D(16, (3, 3), input_shape=(40,40,1), strides=(1, 1),activation=\"relu\", padding=\"same\"))\n",
    "model7.add(Conv2D(16, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model7.add(MaxPooling2D((2,2)))\n",
    "model7.add(Dropout(0.25))\n",
    "model7.add(Conv2D(32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model7.add(Conv2D(32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model7.add(MaxPooling2D((2,2)))\n",
    "model7.add(Dropout(0.25))\n",
    "model7.add(Conv2D(64, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model7.add(Conv2D(64, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model7.add(Dropout(0.25))\n",
    "model7.add(GlobalAveragePooling2D())\n",
    "model7.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model7.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "\n",
    "hist7=model7.fit(x_train, y_train, batch_size=128, epochs=100, verbose=0, class_weight=class_weights, validation_data=(x_val,y_val))\n",
    "plt.plot(hist7.history['loss'],label=\"train_loss\")\n",
    "plt.plot(hist7.history['val_loss'],label=\"val_loss\")\n",
    "plt.title(\"Model Loss BCE CNN 7\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist7.history['acc'],label=\"Train accuracy\" )\n",
    "plt.plot(hist7.history['val_acc'],label=\"Val accuracy\" )\n",
    "plt.title(\"Model Accuracy BCE CNN 7\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "predichos=model7.predict_classes(x_val)\n",
    "print (calculate_metrics(y_val,predichos,'[VAL] Confusion Matrix 100 epochs CNN 7 BCE'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerando data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices_inv=np.load('/work/work_teamEXOPLANET/MTF_margarita/invertidos/MTF_u10_d30.npy')\n",
    "x_train2=matrices_inv[mask_train]\n",
    "y_train2=class2int(labels_train)\n",
    "\n",
    "x_val2=matrices_inv[mask_test]\n",
    "y_val2=class2int(labels_val)\n",
    "\n",
    "x_test2=matrices_inv[mask_unlabeled]\n",
    "\n",
    "\n",
    "x_train2=np.expand_dims(np.asarray(x_train2), axis=-1)\n",
    "x_val2=np.expand_dims(np.asarray(x_val2), axis=-1)\n",
    "x_test2=np.expand_dims(np.asarray(x_test2), axis=-1)\n",
    "\n",
    "print (\"Objetos de entrenamiento:\",x_train2.shape)\n",
    "print (\"Objetos de validación:\",x_val2.shape)\n",
    "print (\"Objetos de testing:\",x_test2.shape)\n",
    "\n",
    "class_weights2 = class_weight.compute_class_weight('balanced', np.unique(y_train2), y_train2)#{0: 3.,   1: 6.,   2: 5.,  3: 3.}\n",
    "print (class_weights2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_o=np.concatenate([x_train, x_train2])\n",
    "y_train_o=np.concatenate([y_train, y_train2])\n",
    "\n",
    "x_val_o=np.concatenate([x_val, x_val2])\n",
    "y_val_o=np.concatenate([y_val, y_val2])\n",
    "\n",
    "x_test_o=np.concatenate([x_test, x_test2])\n",
    "\n",
    "print (\"Objetos de entrenamiento:\",x_train_o.shape)\n",
    "print (\"Objetos de validación:\",x_val_o.shape)\n",
    "print (\"Objetos de testing:\",x_test_o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist=model.fit(x_train_o, y_train_o, batch_size=64, epochs=50, verbose=1, class_weight=class_weights2, validation_data=(x_val_o,y_val_o))\n",
    "plt.plot(hist.history['loss'],label=\"train_loss\")\n",
    "plt.plot(hist.history['val_loss'],label=\"val_loss\")\n",
    "plt.title(\"Model Loss BCE CNN\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist.history['acc'],label=\"Train accuracy\" )\n",
    "plt.plot(hist.history['val_acc'],label=\"Val accuracy\" )\n",
    "plt.title(\"Model Accuracy BCE CNN\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predichos=model.predict_classes(x_val_o)\n",
    "print (calculate_metrics(y_val_o,predichos,'[VAL] Confusion Matrix 50 epochs CNN + reverse LC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist1=model1.fit(x_train_o, y_train_o, batch_size=64, epochs=50, verbose=1, class_weight=class_weights2, validation_data=(x_val_o,y_val_o))\n",
    "plt.plot(hist1.history['loss'],label=\"train_loss\")\n",
    "plt.plot(hist1.history['val_loss'],label=\"val_loss\")\n",
    "plt.title(\"Model Loss BCE CNN1\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist1.history['acc'],label=\"Train accuracy\" )\n",
    "plt.plot(hist1.history['val_acc'],label=\"Val accuracy\" )\n",
    "plt.title(\"Model Accuracy BCE CNN1\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predichos=model1.predict_classes(x_val_o)\n",
    "print (calculate_metrics(y_val_o,predichos,'[VAL] Confusion Matrix 50 epochs CNN 1 + Reverse LC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(64, (3, 3), input_shape=(40,40,1), strides=(1, 1),activation=\"relu\", padding=\"same\"))\n",
    "model2.add(MaxPooling2D((2,2)))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Conv2D(128, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model2.add(Conv2D(256, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "#model1.add(Flatten())\n",
    "model2.add(GlobalAveragePooling2D())\n",
    "model2.add(Dense(256,activation='relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dense(2, activation='softmax'))\n",
    "model2.summary()\n",
    "\n",
    "model2.compile(loss=focal_loss(2,weights=class_weights2),optimizer='adam',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat_o=to_categorical(y_train_o, 2)\n",
    "y_train_cat_o[:3]\n",
    "y_val_cat_o=to_categorical(y_val_o, 2)\n",
    "y_val_cat_o[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist2=model2.fit(x_train_o, y_train_cat_o, batch_size=64, epochs=50, verbose=1, class_weight=class_weights2, validation_data=(x_val_o,y_val_cat_o))\n",
    "plt.plot(hist2.history['loss'],label=\"train_loss\")\n",
    "plt.plot(hist2.history['val_loss'],label=\"val_loss\")\n",
    "plt.title(\"Model Loss Focal CNN1 + Reverse LC\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist2.history['acc'],label=\"Train accuracy\" )\n",
    "plt.plot(hist2.history['val_acc'],label=\"Val accuracy\" )\n",
    "plt.title(\"Model Accuracy Focal CNN1 + Reverse LC\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predichos=model2.predict_classes(x_val_o)\n",
    "print (calculate_metrics(y_val_o,predichos,'[VAL] Confusion Matrix 50 epochs CNN 1 Focal + Reverse LC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Conv2D(32, (3, 3), input_shape=(40,40,1), strides=(1, 1),activation=\"relu\", padding=\"same\"))\n",
    "model3.add(Dropout(0.25))\n",
    "model3.add(Conv2D(32, (3, 3), input_shape=(40,40,1), strides=(1, 1),activation=\"relu\", padding=\"same\"))\n",
    "model3.add(Dropout(0.15))\n",
    "model3.add(GlobalAveragePooling2D())\n",
    "model3.add(Dense(256, activation='relu'))\n",
    "model3.add(Dropout(0.25))\n",
    "model3.add(Dense(128,activation='relu'))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "model4 = Sequential()\n",
    "model4.add(Conv2D(32, (3, 3), input_shape=(40,40,1), strides=(1, 1),activation=\"relu\", padding=\"same\"))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Conv2D(32, (3, 3), input_shape=(40,40,1), strides=(1, 1),activation=\"relu\", padding=\"same\"))\n",
    "model4.add(Dropout(0.1))\n",
    "model4.add(GlobalAveragePooling2D())\n",
    "model4.add(Dense(256, activation='relu'))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Dense(128, activation='relu'))\n",
    "model4.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model4.compile(loss=focal_loss(2,weights=class_weights2),optimizer='adam',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist3=model3.fit(x_train_o, y_train_o, batch_size=64, epochs=100, verbose=1, class_weight=class_weights2, validation_data=(x_val_o,y_val_o))\n",
    "plt.plot(hist3.history['loss'],label=\"train_loss\")\n",
    "plt.plot(hist3.history['val_loss'],label=\"val_loss\")\n",
    "plt.title(\"Model Loss BCE CNN 3 + Reverse LC\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist3.history['acc'],label=\"Train accuracy\" )\n",
    "plt.plot(hist3.history['val_acc'],label=\"Val accuracy\" )\n",
    "plt.title(\"Model Accuracy BCE CNN 3 + Reverse LC\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "predichos=model3.predict_classes(x_val_o)\n",
    "print (calculate_metrics(y_val_o,predichos,'[VAL] Confusion Matrix 50 epochs CNN 3 BCE + Reverse LC'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist4=model4.fit(x_train_o, y_train_cat_o, batch_size=64, epochs=100, verbose=1, class_weight=class_weights2, validation_data=(x_val_o,y_val_cat_o))\n",
    "plt.plot(hist4.history['loss'],label=\"train_loss\")\n",
    "plt.plot(hist4.history['val_loss'],label=\"val_loss\")\n",
    "plt.title(\"Model Loss Focal CNN4 + Reverse LC\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist4.history['acc'],label=\"Train accuracy\" )\n",
    "plt.plot(hist4.history['val_acc'],label=\"Val accuracy\" )\n",
    "plt.title(\"Model Accuracy Focal CNN4 + Reverse LC\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "predichos=model4.predict_classes(x_val_o)\n",
    "print (calculate_metrics(y_val_o,predichos,'[VAL] Confusion Matrix 50 epochs CNN 1 Focal + Reverse LC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist3=model3.fit(x_train_o, y_train_o, batch_size=256 , epochs=50, verbose=1, class_weight=class_weights2, validation_data=(x_val_o,y_val_o))\n",
    "plt.plot(hist3.history['loss'],label=\"train_loss\")\n",
    "plt.plot(hist3.history['val_loss'],label=\"val_loss\")\n",
    "plt.title(\"Model Loss BCE CNN  + Reverse LC\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist3.history['acc'],label=\"Train accuracy\" )\n",
    "plt.plot(hist3.history['val_acc'],label=\"Val accuracy\" )\n",
    "plt.title(\"Model Accuracy BCE CNN  + Reverse LC\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "predichos=model3.predict_classes(x_val_o)\n",
    "print (calculate_metrics(y_val_o,predichos,'[VAL] Confusion Matrix 50 epochs CNN BCE + Reverse LC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = Sequential()\n",
    "model7.add(Conv2D(16, (3, 3), input_shape=(40,40,1), strides=(1, 1),activation=\"relu\", padding=\"same\"))\n",
    "model7.add(Conv2D(16, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model7.add(MaxPooling2D((2,2)))\n",
    "model7.add(Dropout(0.25))\n",
    "model7.add(Conv2D(32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model7.add(Conv2D(32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model7.add(MaxPooling2D((2,2)))\n",
    "model7.add(Dropout(0.25))\n",
    "model7.add(Conv2D(64, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model7.add(Conv2D(64, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"))\n",
    "model7.add(Dropout(0.25))\n",
    "model7.add(GlobalAveragePooling2D())\n",
    "model7.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model7.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "\n",
    "hist7=model7.fit(x_train_o, y_train_o, batch_size=128, epochs=100, verbose=0, class_weight=class_weights2, validation_data=(x_val_o,y_val_o))\n",
    "plt.plot(hist7.history['loss'],label=\"train_loss\")\n",
    "plt.plot(hist7.history['val_loss'],label=\"val_loss\")\n",
    "plt.title(\"Model Loss BCE CNN 7\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist7.history['acc'],label=\"Train accuracy\" )\n",
    "plt.plot(hist7.history['val_acc'],label=\"Val accuracy\" )\n",
    "plt.title(\"Model Accuracy BCE CNN 7\") \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "predichos=model7.predict_classes(x_val_o)\n",
    "print (calculate_metrics(y_val_o,predichos,'[VAL] Confusion Matrix 100 epochs CNN 7 BCE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
