{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys, gc, keras\n",
    "\n",
    "dirpath = os.getcwd().split(\"code\")[0]+\"code/\"\n",
    "sys.path.append(dirpath)\n",
    "from pre_process import clean_LC,generate_representation\n",
    "\n",
    "folder = \"../../KOI_Data/\"\n",
    "#folder_lc = \"/work/work_teamEXOPLANET/KOI_LC/\"\n",
    "folder_lc = \"/media/fmena/KOI_LC/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_kepler = np.load(folder_lc+\"npy/KOI_LC_time.npy\")\n",
    "process_lc = np.load(folder_lc+'/cleaned/LC_kepler_processed.npy')\n",
    "N, T = time_kepler.shape\n",
    "\n",
    "plt.plot(time_kepler[0],process_lc[0])\n",
    "plt.show()\n",
    "print((N,T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([0.       , 0.0204347, 0.0204346, ..., 0.0204347, 0.0204346,\n",
       "       0.0204347]),\n",
       "       array([0.       , 0.0408658, 0.0204329, ..., 0.0204347, 0.0204345,\n",
       "       0.0204348]),\n",
       "       array([0.       , 0.0204347, 0.0204345, ..., 0.0204346, 0.0204346,\n",
       "       0.0204347]),\n",
       "       ...,\n",
       "       array([0.       , 0.0204343, 0.0204342, ..., 0.0204342, 0.020434 ,\n",
       "       0.0204343]),\n",
       "       array([0.       , 0.0204343, 0.0204342, ..., 0.0204342, 0.020434 ,\n",
       "       0.0204343]),\n",
       "       array([0.       , 0.0204342, 0.0204342, ..., 0.0204341, 0.0204341,\n",
       "       0.0204343])], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#borrar nans... arreglo variable\n",
    "coupled_lc = []\n",
    "delta_time = []\n",
    "lens_lc = []\n",
    "for i in range(N):\n",
    "    mask_nan = np.isnan(process_lc[i])\n",
    "    coupled_lc.append(process_lc[i][~mask_nan])\n",
    "    \n",
    "    time = time_kepler[i][~mask_nan]\n",
    "    # calculate delta time --> this could be done after padding is done..\n",
    "    delta_time.append(np.hstack([[0],np.diff(time)]))\n",
    "    lens_lc.append(np.sum(~mask_nan))\n",
    "    \n",
    "coupled_lc = np.asarray(coupled_lc)\n",
    "delta_time = np.asarray(delta_time)\n",
    "delta_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8054,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cada curva de luz dividirla por la desviación estandar..\n",
    "for i in range(coupled_lc.shape[0]):\n",
    "    std_i = coupled_lc[i].std(keepdims=True)\n",
    "    coupled_lc[i] = coupled_lc[i]/std_i \n",
    "coupled_lc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16108,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## data augmentation -- como el paper que nos cito...\n",
    "#flip/mirror cada curva de luz.. (así se duplican los datos..) time: tambn y shift del 0 que sobra..\n",
    "\n",
    "flip_coupled_lc = []\n",
    "flip_delta_time = []\n",
    "for i in range(coupled_lc.shape[0]):    \n",
    "    flip_coupled_lc.append( coupled_lc_scaled[i][::-1] )\n",
    "    flip_delta_time.append(  np.hstack([[0], delta_time[i][1:][::-1]]) )\n",
    "    \n",
    "flip_coupled_lc = np.asarray(flip_coupled_lc)\n",
    "flip_delta_time = np.asarray(flip_delta_time)\n",
    "\n",
    "delta_time = np.concatenate([flip_delta_time,delta_time])\n",
    "coupled_lc = np.concatenate([flip_coupled_lc,coupled_lc])\n",
    "\n",
    "del flip_delta_time, flip_coupled_lc\n",
    "gc.collect()\n",
    "coupled_lc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape with padding:  (16108, 64482)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_lc_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-efcd2f7722e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape with padding: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_lc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mX_lc_scaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_lc_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "max_len = np.max(lens_lc)\n",
    "\n",
    "## do padding with keras..\n",
    "X_time = keras.preprocessing.sequence.pad_sequences(delta_time,maxlen=max_len, value=0,dtype='float32',padding='post')\n",
    "X_lc = keras.preprocessing.sequence.pad_sequences(coupled_lc,maxlen=max_len, value=0,dtype='float32',padding='post')\n",
    "\n",
    "print(\"Shape with padding: \", X_lc.shape)\n",
    "X_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new - Shape:  (16108, 64482, 1)\n"
     ]
    }
   ],
   "source": [
    "#add extra dim\n",
    "X_lc = np.expand_dims(np.squeeze(X_lc),axis=-1)\n",
    "X_time = np.expand_dims(np.squeeze(X_time),axis=-1)\n",
    "\n",
    "N_aug, T, _ = X_lc.shape\n",
    "channels = 2\n",
    "print(\"new - Shape: \", X_lc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Conv1D, Dense, Flatten, MaxPool1D, Reshape, UpSampling1D, Lambda, AveragePooling1D\n",
    "from keras.layers import GlobalAveragePooling1D,GlobalMaxPool1D, TimeDistributed, GRU,LSTM, RepeatVector, SimpleRNN\n",
    "from keras.layers import BatchNormalization, Dropout, ZeroPadding1D, ZeroPadding2D, Cropping1D, Cropping2D, Conv2D, Conv2DTranspose, MaxPool2D,UpSampling2D\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_CNN(it, filters, kernel_s, act='relu', dil_r=1, BN = False, **args):\n",
    "    f1 = Conv1D(filters, kernel_s, activation=act, dilation_rate=dil_r, **args)(it)\n",
    "    if BN:\n",
    "        f1 = BatchNormalization()(f1)\n",
    "    return f1\n",
    "                                                           \n",
    "def conv_bloq(it, filters, kernel_s, pool, drop=0, dil_r=1, act='relu', BN=False,double=False, **arg):\n",
    "    ## **args could be any other conv1d parameter\n",
    "    f1 = add_CNN(it, filters, kernel_s, act=act, dil_r=dil_r, BN = BN, **args)\n",
    "    if double:\n",
    "        f1 = add_CNN(f1, filters, kernel_s, act=act, dil_r=dil_r, BN = BN, **args)\n",
    "        \n",
    "    if pool!= 0 and dil_r ==1:\n",
    "        #f1 = MaxPool1D(pool_size=pool, strides=pool, padding='valid')(f1)\n",
    "        f1 = AveragePooling1D(pool_size=pool, strides=pool, padding='valid')(f1)\n",
    "    if drop != 0:\n",
    "        f1 = Dropout(drop)(f1)\n",
    "    return f1\n",
    "\n",
    "def encoder_model_CNN1D(input_dim, channels, L=1, filters=8, kernel_s =10, pool=5, BN=False, drop=0,\n",
    "                        dil_r=1, flatten =True,time=False,double=False, **args): \n",
    "    #parametros estructurales-- args es cuqluier parameter de conv1d\n",
    "    it = Input(shape=(input_dim,channels))  #fixed length..\n",
    "    f1 = it\n",
    "    start_f = filters\n",
    "    for l in range(L):\n",
    "        f1 = conv_bloq(f1, filters, kernel_s, pool,conv_pool=conv_pool, drop=drop,dil_r=dil_r,BN=BN,double=double, **args) \n",
    "        \n",
    "        filters = int(filters*2)\n",
    "        filters = min(128, filters)\n",
    "        if time:\n",
    "            filters = min(32, filters)\n",
    "        if dil_r != 1:\n",
    "            dil_r = int(dil_r*2)\n",
    "            \n",
    "    if flatten:\n",
    "        f1 = Flatten()(f1)\n",
    "    else:\n",
    "        #f1 = GlobalMaxPool1D()(f1)\n",
    "        f1 = GlobalAveragePooling1D()(f1)\n",
    "    return Model(inputs=it, outputs=f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_s = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'get_default_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9366f660bb80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_model_CNN1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-3e2297a5963c>\u001b[0m in \u001b[0;36mencoder_model_CNN1D\u001b[0;34m(input_dim, channels, L, filters, kernel_s, pool, BN, conv_pool, drop, padding, dil_r, time)\u001b[0m\n\u001b[1;32m     20\u001b[0m def encoder_model_CNN1D(input_dim, channels, L=1, filters=8,kernel_s =10,\n\u001b[1;32m     21\u001b[0m                         pool=5,BN=False,conv_pool=False,drop=0,padding='same',dil_r=1,time=False ): #parametros estructurales\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#fixed length..\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mstart_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/ohpc/pub/moduledeps/anaconda3/lib/python3.7/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mInput\u001b[0;34m(shape, batch_shape, name, dtype, sparse, tensor)\u001b[0m\n\u001b[1;32m   1453\u001b[0m                              \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1454\u001b[0m                              \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m                              input_tensor=tensor)\n\u001b[0m\u001b[1;32m   1456\u001b[0m     \u001b[0;31m# Return tensor including _keras_shape and _keras_history.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m     \u001b[0;31m# Note that in this case train_output and test_output are the same pointer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/ohpc/pub/moduledeps/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/ohpc/pub/moduledeps/anaconda3/lib/python3.7/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, batch_size, batch_input_shape, dtype, input_tensor, sparse, name)\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'input'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_uid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/ohpc/pub/moduledeps/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_uid\u001b[0;34m(prefix)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \"\"\"\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_default_graph'"
     ]
    }
   ],
   "source": [
    "#Kernel 8 y pool 3\n",
    "#comenzar con 8 filtros\n",
    "#en salida deberian haber approx 200-10k o 5k\n",
    "\n",
    "encoder   = encoder_model_CNN1D(T, 1, L=5, filters=16, pool=3, kernel_s=5, drop=0.0) \n",
    "encoder_t = encoder_model_CNN1D(T, 1, L=5, filters=16, pool=3, kernel_s=5, drop=0.0, time=True) #model\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## original: C aguirre (T=500) con idea de steps..\n",
    "encoder  = encoder_model_CNN1D(T, 1, L=2, filters=32, pool=2, kernel_s=40, drop=0.25) \n",
    "ncoder_t = encoder # pero la curva son deltas tambn...\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine two \"tower\"\n",
    "it_time = Input(shape=X_time.shape[1:])\n",
    "it_lc = Input(shape=X_lc.shape[1:])\n",
    "encoder_time = encoder_t(it_time)\n",
    "encoder_lc = encoder(it_lc)\n",
    "concat_encoder = keras.layers.Concatenate()([encoder_time,encoder_lc]) #or multiply?\n",
    "\n",
    "f1 = Dropout(0.5)(concat_encoder)\n",
    "f1 = Dense(128, activation='relu')(concat_encoder)\n",
    "f1 = Dropout(0.5)(f1)\n",
    "out = Dense(1, activation='sigmoid')(f1)\n",
    "\n",
    "CNN_all = Model([it_time,it_lc], out)\n",
    "CNN_all.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN casual+dilation \n",
    "> WaveNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder  = encoder_model_CNN1D(T, 1, L=.., filters=.., kernel_s=.., drop=0.0, flatten=False,dil_r=2, padding='causal' ) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
